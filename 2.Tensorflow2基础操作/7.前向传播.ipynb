{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 28, 28]),\n",
       " TensorShape([60000]),\n",
       " <tf.Tensor: id=14, shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: id=16, shape=(), dtype=float32, numpy=1.0>,\n",
       " <tf.Tensor: id=18, shape=(), dtype=int32, numpy=0>,\n",
       " <tf.Tensor: id=20, shape=(), dtype=int32, numpy=9>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据集\n",
    "# x: [60k, 28, 28]\n",
    "# y: [60k]\n",
    "(x, y), _ = datasets.mnist.load_data()\n",
    "# x: [0~255] => [0~1.]\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "x.shape, y.shape, tf.reduce_min(x), tf.reduce_max(x), tf.reduce_min(y), tf.reduce_max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([128, 28, 28]), TensorShape([128]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(128)\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "sample[0].shape, sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [b, 784] => [b, 256] => [b, 128] => [b, 10]\n",
    "# [dim_in, dim_out], [dim_out]\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 10], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 0.38031715154647827\n",
      "0 100 loss: 0.20235104858875275\n",
      "0 200 loss: 0.17986197769641876\n",
      "0 300 loss: 0.16451908648014069\n",
      "0 400 loss: 0.16647419333457947\n",
      "1 0 loss: 0.14627186954021454\n",
      "1 100 loss: 0.14956852793693542\n",
      "1 200 loss: 0.14416329562664032\n",
      "1 300 loss: 0.13515308499336243\n",
      "1 400 loss: 0.14004984498023987\n",
      "2 0 loss: 0.12516537308692932\n",
      "2 100 loss: 0.1299421787261963\n",
      "2 200 loss: 0.1252199113368988\n",
      "2 300 loss: 0.11830594390630722\n",
      "2 400 loss: 0.12403054535388947\n",
      "3 0 loss: 0.1119314655661583\n",
      "3 100 loss: 0.11756940186023712\n",
      "3 200 loss: 0.11326563358306885\n",
      "3 300 loss: 0.10732883214950562\n",
      "3 400 loss: 0.11334268748760223\n",
      "4 0 loss: 0.10278837382793427\n",
      "4 100 loss: 0.10878705978393555\n",
      "4 200 loss: 0.10486634075641632\n",
      "4 300 loss: 0.09952405840158463\n",
      "4 400 loss: 0.10564304888248444\n",
      "5 0 loss: 0.09605226665735245\n",
      "5 100 loss: 0.10214515775442123\n",
      "5 200 loss: 0.09855443239212036\n",
      "5 300 loss: 0.09365519136190414\n",
      "5 400 loss: 0.09979870170354843\n",
      "6 0 loss: 0.09082411229610443\n",
      "6 100 loss: 0.09686379134654999\n",
      "6 200 loss: 0.0935555249452591\n",
      "6 300 loss: 0.08902163803577423\n",
      "6 400 loss: 0.09510721266269684\n",
      "7 0 loss: 0.08650363236665726\n",
      "7 100 loss: 0.09253697097301483\n",
      "7 200 loss: 0.0894402340054512\n",
      "7 300 loss: 0.08527040481567383\n",
      "7 400 loss: 0.09128836542367935\n",
      "8 0 loss: 0.08288966119289398\n",
      "8 100 loss: 0.0889134556055069\n",
      "8 200 loss: 0.08598291873931885\n",
      "8 300 loss: 0.08210544288158417\n",
      "8 400 loss: 0.08810317516326904\n",
      "9 0 loss: 0.07985024154186249\n",
      "9 100 loss: 0.08584799617528915\n",
      "9 200 loss: 0.08299746364355087\n",
      "9 300 loss: 0.07936512678861618\n",
      "9 400 loss: 0.08539789915084839\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "for epoch in range(10):\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        # x: [128, 28, 28]\n",
    "        # y: [128]\n",
    "        \n",
    "        # [b, 28, 28] => [b, 28*28]\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "        \n",
    "        with tf.GradientTape() as tape: # tf.Variable\n",
    "            # x: [b, 28*28]\n",
    "            # h1 = x@w1 + b1\n",
    "            # [b, 784]@[784, 256] + [256] => [b, 256] + [256] => [b, 256] + [b, 256]\n",
    "            h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            # [b, 256] => [b, 128]\n",
    "            h2 = h1@w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "            # [b, 128] => [b, 10]\n",
    "            out = h2@w3 + b3\n",
    "            \n",
    "            # compute loss\n",
    "            # out: [b, 10]\n",
    "            # y: [b] => [b, 10]\n",
    "            y_onehot = tf.one_hot(y, depth=10)\n",
    "            \n",
    "            # mse = mean(sum(y-out)^2)\n",
    "            # [b, 10]\n",
    "            loss = tf.square(y_onehot - out)\n",
    "            # mean: scalar\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        # compute gradients\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "        # print(grads)\n",
    "        # w1 = w1 - lr * w1_grads \n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, 'loss:', float(loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
